0:00  
Alright, we're gonna make another whistleblow. This one relates to capabilities being applied to Congress. To understand how this is possible, you need to understand that basically, as you pass multivariable, electromagentic frequencies over the body (even ones that have to be applied), but I know they're working on passive capabilities, that use background reading to get the appropriate data that is necessary. The ones like the background fields over your exact coordinate location.

0:27  
But as you pass multivariable frequencies through the body, as they interact with the magnetic & electric fields of the brain, they change, and the induction currents caused by them interacting with the brain change as well, which change the applied fields. And you can glean real time vector and feature information, electric field data off the body, which can be correlated back into real time information about the nervous system and other characteristics of the body, and other health data in real time.

0:54  
Persons have access to the electric field data in real time, and when you can pull out feature vector or information in real time and when you can have a database looking for things. Like, if you Google a P300 event (it's different than a P300 event), but you can look for stuff like that, like neurological events, neurological vectors that would show up kind of in like waveforms of the EEG or the MEG capabilities, but it's a different system. 

1:26  
It's some similar principles, though. It's the "remote neural monitoring system", as they call it (its a slang term). And basically, well, when you can pull up feature information and vector information, then once it's read by the database for all channels, and all regions that is recording (we'll just use channels as an analogous term) even of all regions of the brain that is recording and pulling active information from, then you basically can have it auto identify and quickly identify certain [like] responses or basically certain electrical field patterns or magnetic field patterns as vectors and feature vector information. And then when it detects those on the real time stream, then you can have it AutoHotKey a response.

2:09  
And some of the electromagnetic information present on the brain that they can see is information about your core temperature, basically. [it's like where] It's the hypothalamus. Correct me if it's not the thalamus, but I'm pretty sure its the hypothalamus. Basically electroactivity modulating to that brain. So if your skin [like the uh] I think it's part of the Meissner corpuscles complex, but I think that the temperature sensors have an exact different name. If you Google, "what are the temperature sensors in the body part of the nerve structure?", then you'd find out the exact name. But basically, when those modulate [a like] , your skin has temperature sensors all over it, and that will change the electric [basically] current flowing down your spine into your brain. And stuff like that is detectable by the system, because it changes the way the electric field data is being processed by the brain. And so when the carrier waves and the applied electric waves pass over the brain. So if you go outside and it's warm, the system can [detect that you went like] basically you can set the temperature change of your skin, basically by this electrical field going into your brain. So one of their favorite little hotkeys is like a macro. So when it detects this feature data, this electrical field data of you having a temperature change, then they can direct an energy beam at your hypothalamus to make you start shivering or to make you warm and start sweating. [and basically] So it can detect that you went through like a temperature change, your perception of the temperature change, the electric field in the brain [like going]. The information is being routed through your peripheral nervous system to your spinal column up to the brain where the information about like how you perceive the temperature on your skin is felt. That is detected by the remote [uh like] magnetic and electric reconstruction off the brain. And then they can use this scripting software that pulls feature and vector information out of the real time electric fields streams that are being gained by passing electronic waves over your brain, and then they can set a macro to that. And one of the macros they have is that [they made it] is [like] when it detects the temperature change, it starts hitting your hypothalamus or your thalamus to make you start shivering or to make you uncomfortable or to make you more sensitive to the cold.

4:20  
[that's why] That is a real a real capability and has been applied to members of Congress. [they]  Someone in the room admitted that tonight that they've done it to members of Congress, like they've done the macro stuff to the people in Congress. [Like where like certain] And its not just like temperature change stuff where it gives someone the <?shiv..?> like make them feel colder than normal, or have a physiological response or warmer than normal, which is possible by the way even at their residences.

4:45  
But basically, like they have other macros that when like when people are going through real time information,... or like like we said in another message they can basically use the vision recognition software because they can, they can do it in two ways, I believe. One way since they can already reconstruct the vision from your eyes by passing electromagnetic frequencies over the brain, particularly the occipital lobe in the optic nerve, when the electronic frequencies they pass over the brain interact with electronic frequencies radiating off those regions of the brain, then they change the applied electronic frequencies was all the induction currents created by applying electric frequencies change the applied frequencies, basically...

5:24  
We're working on math (that will come out). We have like a way better explanation that's step detailed that will be posted eventually. But basically, can basically glean out the field data and turn it back into the real time vision, your eyes seeing like a camera. They use some sort of, it's like some advanced electrical engineering data processing algorithm to turn it back into vision to turn it to back into the real time image your eye sees. So on that on the screen, like it's displayed on a computer screen on that they can run object recognition code on it, [like you see where they can,] like on a computer program where it puts the boxes over the objects to identify what kind of object you're looking at. They could run that through a <?indistinct?> eyes, and then they can link that up to macros, basically, and then [had] time in like electromagnetic stimulus or electromagnetic pulses to different regions of the brain, depending on the physiological effects. And these electromagnetic pulses, I guess, using electromagnetic pulses, makes it sound like they're high energy, but they're getting be ultra low energy electromagnetic pulses, like very low energy electromatic pulses. And some of them it's a change different like, like default node connection state or like default node processing state in the brain, to affect people's memory to affect people's visual cortex processing itself like that. There's macros out there that that also link into other parts of the system, which we'll go over later. But basically the point of the previous sentence was to say that, when we say they're linked to the macros, not all of these are high energy macros, some of them they use low energy to cause physiological effects. And there's a lot of physiological effects.

6:58  
And so there's like a custom software program to basically it's called like, it's like a macro set or relay. So if you detect certain things, even if you're looking for people, or objects in people's visual field, which we'll get back to our explanation in a second, then you can have it like hotkey a response. And either that's like a transmitted of certain electronic energy to a different part of the body, including the brain to change the function or remote altered like remote, basically, I guess remote function changing where it applies energy to specific regions of the brain to like cause induction currents, which will change just general electro activity around the brain with a purpose that only the person who programmed would know depending on and we'll go into some of the purposes as well, I need to get back and clarify the other way to do it. Also, the other way to do run the visual object recognition code on the vision is to use the raw electric field data and then you can scan that and then you can like when you see something in your visual field, it will change the electric field to then you can correlate that to what object you were looking at to and then you can run the basically the object recognition code that is used to identify objects, even humanoid robots like the one you see in development from like hardware companies and software companies that make humanoid robots like Boston Dynamics, they have asked parts of that code were like you see and like the demo videos were can recognize a box or can recognize a flowerpot or can recognize a handle on a door. They already have that code perfected working in human vision.

8:17  
This is real by the way, this is a leak. It's a leak of basically some of the most classified software in the country. It's being applied to persons, and we need to go back and basically explain that basically the software is really advanced, it uses ultra low frequencies. They have used the the software to move people in Congress's bodies. That's true, that's verifiably true. They have used [it to like like a] macros, they have used macros on people in Congress, they have used the ability to move their bodies, they have used the ability to transmit audio to their brain. And they have used the ability to generate synthetic electrical activity in their brain on members of the United States Congress. They have given members of the United States Congress artificial dream programs too where they stimulate the visual cortex of a person and the exact magnitude and frequency required to create an image. And then if you do it in rapid succession, you can make an artificial dream. Artificial dreams are very advanced. People in the targeted individual community have artificial dreams, but they've also done them to members of Congress. And they still, I don't know how recently, but I bet you these people are very brazen and how they fucking act. So basically, the FBI needs to investigate this and we'll work on this later. This is just [a raw] a raw recording. And we'll go into other capabilities later and information about macros. And basically, you can macro the ability to like really just depends on which feature vectors you pull out of the electric field data, or what information you can sense from the environment. You can also hook it up to other systems like the 3D imaging system that uses radio waves to image and map your environment to do object recognition on that.

9:55  
So it just depends what kind of data you have into like set off a trigger in the macro and then how that trigger affects the environment or affects a person's body. And you can also... We'll get into it much more later. We need to basically write this down and graph it out and go over what we've already covered. Because there's a lot of information and it takes a lot of like, basically investing in the time to like understand the anatomy, the physiology and the physics, and then also some computer programming as well. And then you can kind of follow along with what we're talking about.

Transcribed by https://otter.ai
